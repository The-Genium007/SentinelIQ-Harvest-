# ğŸ“ **Guide Complet SentinelIQ Harvest v2.0**

_Guide pour dÃ©veloppeurs dÃ©butants et intermÃ©diaires_

---

## ğŸ“š **Table des MatiÃ¨res**

1. [ğŸ¯ Vue d'ensemble](#overview)
2. [ğŸ—ï¸ Architecture du systÃ¨me](#architecture)
3. [ğŸš€ Installation et dÃ©marrage](#installation)
4. [ğŸ“– Comprendre WireScanner](#wirescanner)
5. [ğŸ§  Comprendre Cortex](#cortex)
6. [ğŸ’¾ SystÃ¨me de base de donnÃ©es](#database)
7. [ğŸ“‹ Logs et monitoring](#logs)
8. [ğŸ”§ Scripts NPM disponibles](#scripts)
9. [ğŸ› ï¸ Migration et compatibilitÃ©](#migration)
10. [ğŸ’¡ Conseils pour dÃ©veloppeurs](#tips)
11. [ğŸ› DÃ©pannage](#troubleshooting)

---

## ğŸ¯ **Vue d'ensemble** {#overview}

### **Qu'est-ce que SentinelIQ Harvest ?**

SentinelIQ Harvest est un systÃ¨me automatisÃ© de **collecte et d'analyse d'articles** qui fonctionne en deux Ã©tapes principales :

1. **ğŸ•·ï¸ WireScanner** : Collecte les liens d'articles depuis des flux RSS
2. **ğŸ§  Cortex** : Analyse le contenu des articles collectÃ©s

### **ProblÃ¨me rÃ©solu**

- âŒ **Avant** : Surveillance manuelle des sites web, perte d'informations importantes
- âœ… **AprÃ¨s** : Collecte automatisÃ©e 24/7, analyse intelligente du contenu

### **Technologies utilisÃ©es**

- **Runtime** : Node.js (migrÃ© depuis Bun)
- **Base de donnÃ©es** : Supabase (PostgreSQL)
- **Scraping** : Puppeteer pour l'analyse des pages web
- **Parsing RSS** : xml2js pour traiter les flux RSS
- **Process management** : Modules Node.js natifs

---

## ğŸ—ï¸ **Architecture du systÃ¨me** {#architecture}

### **Vue d'ensemble de l'architecture**

```
ğŸ“ SentinelIQ Harvest/
â”œâ”€â”€ ğŸ•·ï¸ WireScanner/          # Module de collecte RSS
â”œâ”€â”€ ğŸ§  Cortex/               # Module d'analyse de contenu
â”œâ”€â”€ ğŸ’¾ database/             # Couche d'accÃ¨s aux donnÃ©es
â”œâ”€â”€ ğŸ› ï¸ utils/               # Utilitaires (logs, etc.)
â”œâ”€â”€ ğŸ“‹ logs/                # Fichiers de logs
â”œâ”€â”€ ğŸ“„ *.md                 # Documentation
â””â”€â”€ ğŸ“¦ package.json         # Configuration NPM
```

### **Flux de donnÃ©es**

```
1. ğŸŒ Sites RSS â†’ 2. ğŸ•·ï¸ WireScanner â†’ 3. ğŸ’¾ Base de donnÃ©es (URLs)
                                          â†“
6. ğŸ“Š Rapport final â† 5. ğŸ’¾ Base de donnÃ©es (Articles) â† 4. ğŸ§  Cortex
```

### **Cycle de vie d'un article**

1. **DÃ©couverte** : WireScanner trouve un lien dans un flux RSS
2. **Stockage URL** : Le lien est sauvegardÃ© dans `articlesUrl`
3. **Analyse** : Cortex rÃ©cupÃ¨re le contenu de la page
4. **Traitement** : Le contenu est nettoyÃ© et analysÃ©
5. **Stockage final** : L'article complet est sauvÃ© dans `articles`

---

## ğŸš€ **Installation et dÃ©marrage** {#installation}

### **PrÃ©requis**

```bash
# VÃ©rifier Node.js (version 16+ recommandÃ©e)
node --version

# VÃ©rifier npm
npm --version
```

### **Installation**

```bash
# 1. Cloner le projet
git clone [votre-repo]
cd "SentinelIQ Harvest"

# 2. Installer les dÃ©pendances
npm install

# 3. Configurer l'environnement
cp key.env.example key.env
# Ã‰diter key.env avec vos credentials Supabase
```

### **Configuration key.env**

```bash
# Base de donnÃ©es Supabase
SUPABASE_URL=https://votre-project.supabase.co
SUPABASE_KEY=votre-clÃ©-api

# Logs (optionnel)
DEBUG=true
VERBOSE=true

# Cortex (optionnel)
CORTEX_PORT=3001
CORTEX_LOG_LEVEL=INFO
```

### **Premier dÃ©marrage**

```bash
# Test de la configuration
npm run diagnostic

# Test de la base de donnÃ©es
npm run db:test

# Lancement d'un test de scrapping
npm run scrapping
```

---

## ğŸ“– **Comprendre WireScanner** {#wirescanner}

### **RÃ´le de WireScanner**

WireScanner est le **collecteur RSS** du systÃ¨me. Il :

- ğŸ“¡ Surveille les flux RSS configurÃ©s
- ğŸ” Extrait les liens d'articles
- ğŸ’¾ Sauvegarde les URLs dans la base de donnÃ©es
- ğŸš€ Lance automatiquement Cortex ensuite

### **Architecture WireScanner v2.0**

```
WireScanner/
â”œâ”€â”€ ğŸ“‹ config.js             # Configuration centralisÃ©e
â”œâ”€â”€ ğŸ“Š performanceManager.js # Monitoring des performances
â”œâ”€â”€ ğŸ”„ feedProcessor.js      # Traitement des flux RSS
â”œâ”€â”€ ğŸ’¾ dataManager.js        # Gestion base de donnÃ©es
â”œâ”€â”€ ğŸ› ï¸ utils.js             # Utilitaires rÃ©utilisables
â”œâ”€â”€ ğŸš€ crawlUrl.optimized.js # Module principal v2.0
â”œâ”€â”€ ğŸ”„ migration.js          # Outils de migration
â””â”€â”€ ğŸ¯ start.js             # Point d'entrÃ©e
```

### **Optimisations v2.0**

#### **ğŸ§  Gestion mÃ©moire**

```javascript
// Garbage collection automatique
setInterval(() => {
  if (global.gc && memoryUsage > threshold) {
    global.gc();
  }
}, 60000);

// Cache intelligent avec TTL
const cache = new Map();
// Auto-nettoyage aprÃ¨s 5 minutes
```

#### **âš¡ Traitement concurrent**

```javascript
// Limite la charge systÃ¨me
const CONCURRENT_FEEDS = 5; // 5 flux max simultanÃ©s
const CONCURRENT_ARTICLES = 10; // 10 articles max simultanÃ©s

// Batching pour la base de donnÃ©es
const BATCH_SIZE = 50; // 50 articles par lot
```

#### **ğŸ“Š Monitoring en temps rÃ©el**

```javascript
// Surveillance automatique
const monitor = {
  memoryUsage: process.memoryUsage(),
  feedsProcessed: 0,
  articlesFound: 0,
  errorRate: 0,
};
```

### **Comment utiliser WireScanner**

#### **Utilisation basique**

```bash
# Scrapping automatique (configurÃ© en cron)
npm run wire-scanner

# Scrapping manuel
npm run scrapping
```

#### **Utilisation avancÃ©e**

```javascript
import { startWireScanner } from "./WireScanner/start.js";

// Configuration personnalisÃ©e
const options = {
  maxFeeds: 10,
  enableCortex: true,
  logLevel: "DEBUG",
};

const results = await startWireScanner(options);
console.log(`${results.articlesFound} articles trouvÃ©s`);
```

### **Monitoring WireScanner**

```bash
# Voir les statistiques
npm run diagnostic

# Analyser les logs WireScanner
grep "WireScanner" logs/scraping.log | tail -50

# Voir l'utilisation mÃ©moire
node -e "console.log(process.memoryUsage())"
```

---

## ğŸ§  **Comprendre Cortex** {#cortex}

### **RÃ´le de Cortex**

Cortex est le **cerveau analytique** du systÃ¨me. Il :

- ğŸ” Analyse le contenu des pages web
- ğŸ“ Extrait le texte principal des articles
- ğŸ§¹ Nettoie et structure le contenu
- ğŸ’¾ Sauvegarde les articles traitÃ©s

### **Architecture Cortex v2.0**

```
Cortex/
â”œâ”€â”€ âš™ï¸ config.js              # Configuration Puppeteer et performance
â”œâ”€â”€ ğŸ“Š performanceManager.js   # Monitoring spÃ©cialisÃ© Puppeteer
â”œâ”€â”€ ğŸ•·ï¸ scrapingEngine.js      # Pool de browsers et scraping
â”œâ”€â”€ ğŸ’¾ dataManager.js          # Gestion donnÃ©es avec cache
â”œâ”€â”€ ğŸ” contentProcessor.js     # Traitement intelligent du contenu
â”œâ”€â”€ ğŸš€ cortexOptimized.js      # Orchestrateur principal v2.0
â”œâ”€â”€ ğŸ”„ migration.js           # Migration et compatibilitÃ©
â””â”€â”€ ğŸ¯ start.js              # Point d'entrÃ©e dual
```

### **Optimisations v2.0**

#### **ğŸŒ Pool de browsers Puppeteer**

```javascript
// RÃ©utilisation des instances browser
class BrowserPool {
  constructor(poolSize = 2) {
    this.browsers = [];
    this.available = [];
    this.busy = [];
  }

  async getBrowser() {
    // RÃ©cupÃ¨re un browser disponible ou en crÃ©e un nouveau
  }

  releaseBrowser(browser) {
    // Remet le browser dans le pool
  }
}
```

#### **ğŸ§  Gestion mÃ©moire Puppeteer**

```javascript
// Configuration optimisÃ©e pour Puppeteer
const browserOptions = {
  headless: true,
  args: [
    "--no-sandbox",
    "--disable-dev-shm-usage",
    "--disable-images", // Ã‰conomise de la mÃ©moire
    "--disable-javascript", // Optionnel selon le site
  ],
};

// Nettoyage automatique des pages
page.on("response", () => {
  if (responseCount > 50) {
    page.close(); // Ferme la page si trop de ressources
  }
});
```

#### **ğŸ“Š Traitement concurrent intelligent**

```javascript
// Limite adaptative selon les ressources
const getOptimalConcurrency = () => {
  const memUsage = process.memoryUsage().heapUsed / 1024 / 1024;

  if (memUsage > 200) return 1; // Mode Ã©conomie
  if (memUsage > 100) return 2; // Mode normal
  return 3; // Mode performance
};
```

### **Comment utiliser Cortex**

#### **Utilisation basique**

```bash
# Analyse automatique (lancÃ© aprÃ¨s WireScanner)
npm run cortex

# Analyse manuelle
node Cortex/start.js
```

#### **Utilisation avancÃ©e**

```javascript
import { startCortex } from "./Cortex/start.js";

// Configuration personnalisÃ©e
const options = {
  maxArticles: 50,
  enableMonitoring: true,
  enableBatching: true,
  useOptimized: true, // Utilise la version v2.0
};

const results = await startCortex(options);
console.log(`${results.results.articlesScraped} articles analysÃ©s`);
```

#### **Migration vers v2.0**

```javascript
import { migrateCortex } from "./Cortex/start.js";

// Migration automatique
const migrationResults = await migrateCortex({
  createBackup: true,
  testNewVersion: true,
});

if (migrationResults.success) {
  console.log("Migration v2.0 rÃ©ussie !");
}
```

### **Monitoring Cortex**

```bash
# Statut de Cortex
node -e "
import('./Cortex/start.js').then(m => {
    console.log(JSON.stringify(m.getCortexStatus(), null, 2));
});
"

# Voir les logs Cortex
tail -f logs/scraping.log | grep "Cortex"

# Analyser les performances
npm run diagnostic | grep -A 10 "Cortex"
```

---

## ğŸ’¾ **SystÃ¨me de base de donnÃ©es** {#database}

### **Architecture de la couche database/**

La couche `database/` centralise **tous les accÃ¨s** Ã  Supabase avec une architecture moderne :

```
database/
â”œâ”€â”€ ğŸ”Œ client.js           # Client Supabase singleton
â”œâ”€â”€ ğŸ“ baseRepository.js   # Classe CRUD de base
â”œâ”€â”€ ğŸ“¡ rssRepository.js    # Repository flux RSS
â”œâ”€â”€ ğŸ“„ articleRepository.js # Repositories articles
â””â”€â”€ ğŸ¯ index.js           # Point d'entrÃ©e + compatibilitÃ©
```

### **Tables de la base de donnÃ©es**

#### **1. `ListUrlRss` - Flux RSS surveillÃ©s**

```sql
CREATE TABLE ListUrlRss (
    id SERIAL PRIMARY KEY,
    url TEXT UNIQUE NOT NULL,       -- URL du flux RSS
    created_at TIMESTAMP DEFAULT NOW()
);
```

#### **2. `articlesUrl` - URLs d'articles dÃ©couverts**

```sql
CREATE TABLE articlesUrl (
    id SERIAL PRIMARY KEY,
    url TEXT UNIQUE NOT NULL,       -- URL de l'article
    titre TEXT,                     -- Titre depuis le RSS
    description TEXT,               -- Description depuis le RSS
    datePublication TIMESTAMP,      -- Date de publication
    created_at TIMESTAMP DEFAULT NOW()
);
```

#### **3. `articles` - Articles analysÃ©s**

```sql
CREATE TABLE articles (
    id SERIAL PRIMARY KEY,
    urlArticle TEXT UNIQUE NOT NULL, -- URL de l'article
    title TEXT NOT NULL,            -- Titre extrait
    content TEXT NOT NULL,          -- Contenu complet
    dateRecuperation TIMESTAMP,     -- Date d'analyse
    datePublication TIMESTAMP,      -- Date de publication
    source TEXT,                    -- Source (WireScanner/Cortex)
    metadata JSONB                  -- MÃ©tadonnÃ©es additionnelles
);
```

### **Utilisation des repositories**

#### **Repository RSS**

```javascript
import { rssRepository } from "./database/index.js";

// RÃ©cupÃ©rer tous les flux RSS actifs
const feeds = await rssRepository.getAllFeeds();
console.log(`${feeds.length} flux RSS configurÃ©s`);

// Ajouter un nouveau flux
await rssRepository.addFeed({
  url_rss: "https://example.com/rss.xml",
});

// VÃ©rifier qu'un flux existe
const exists = await rssRepository.findByUrl("https://example.com/rss.xml");
```

#### **Repository ArticlesUrl**

```javascript
import { articleUrlRepository } from "./database/index.js";

// RÃ©cupÃ©rer les articles non traitÃ©s
const unprocessed = await articleUrlRepository.findAll({
  limit: 100,
  orderBy: { created_at: "DESC" },
});

// Ajouter un nouvel article dÃ©couvert
await articleUrlRepository.addArticle({
  url: "https://example.com/article-1",
  titre: "Titre de l'article",
  description: "Description courte",
  datePublication: new Date().toISOString(),
});

// VÃ©rifier qu'un article existe dÃ©jÃ 
const exists = await articleUrlRepository.existsByUrl(articleUrl);
```

#### **Repository Articles (traitÃ©s)**

```javascript
import { articleRepository } from "./database/index.js";

// Sauvegarder un article analysÃ©
await articleRepository.saveProcessedArticle({
  urlArticle: "https://example.com/article-1",
  title: "Titre extrait de la page",
  content: "Contenu complet de l'article...",
  datePublication: "2025-01-15T10:30:00Z",
  source: "Cortex",
  metadata: {
    author: "John Doe",
    wordCount: 1500,
    extractedAt: new Date().toISOString(),
  },
});

// VÃ©rifier qu'un article a Ã©tÃ© traitÃ©
const isProcessed = await articleRepository.exists({
  urlArticle: articleUrl,
});

// RÃ©cupÃ©rer les statistiques
const stats = await articleRepository.getStats();
console.log(`${stats.total} articles traitÃ©s`);
```

### **CompatibilitÃ© avec l'ancien code**

La nouvelle couche maintient la **compatibilitÃ©** avec l'ancien code :

```javascript
// âš ï¸ Ancien code (encore fonctionnel mais deprecated)
import { getRssFeeds } from "./WireScanner/supabaseUtils.js";
// â†’ Affiche un warning de migration

// âœ… Nouveau code (recommandÃ©)
import { rssRepository } from "./database/index.js";
```

### **Outils de diagnostic database**

```bash
# Test de connexion simple
npm run db:test

# SantÃ© complÃ¨te du systÃ¨me
npm run db:health

# Statistiques globales
npm run db:stats

# Analyse des schÃ©mas
npm run db:schema

# Test de compatibilitÃ© ancien/nouveau
npm run db:compatibility
```

---

## ğŸ“‹ **Logs et monitoring** {#logs}

### **Structure des logs**

```
logs/
â”œâ”€â”€ ğŸ“Š system.log     # Logs systÃ¨me gÃ©nÃ©raux
â”œâ”€â”€ ğŸ•·ï¸ scraping.log  # Logs WireScanner + Cortex
â”œâ”€â”€ ğŸ› error.log     # Erreurs uniquement
â”œâ”€â”€ ğŸ” debug.log     # Logs de dÃ©bogage dÃ©taillÃ©s
â”œâ”€â”€ ğŸŒ webhook.log   # Logs webhooks (deprecated)
â””â”€â”€ â° cron.log      # Logs des tÃ¢ches cron
```

### **Niveaux de logging**

1. **ERROR** : Erreurs critiques uniquement
2. **WARN** : Avertissements importants
3. **INFO** : Informations gÃ©nÃ©rales (dÃ©faut)
4. **DEBUG** : DÃ©tails techniques pour le dÃ©bogage

### **Configuration des logs**

```javascript
// Dans key.env
DEBUG=true              # Active les logs debug
VERBOSE=true           # Logs trÃ¨s dÃ©taillÃ©s
CORTEX_LOG_LEVEL=INFO  # Niveau pour Cortex spÃ©cifiquement
```

### **Utilisation du systÃ¨me de logs**

```javascript
import { logger } from "./utils/logger.js";

// Logs basiques
logger.info("DÃ©marrage du traitement", "MonModule");
logger.warning("Ressource faible", "MonModule");
logger.error("Erreur critique", "MonModule");

// Logs avec donnÃ©es
logger.debug("RÃ©sultats traitement", "MonModule", {
  articlesFound: 25,
  processingTime: 1500,
  memoryUsage: "150MB",
});
```

### **Scripts d'analyse des logs**

```bash
# Analyse complÃ¨te des logs
npm run logs:analyze

# RÃ©sumÃ© des logs rÃ©cents
npm run logs:summary

# Nettoyage des anciens logs
npm run logs:clean

# Voir les erreurs rÃ©centes uniquement
tail -50 logs/error.log

# Suivre les logs en temps rÃ©el
tail -f logs/scraping.log
```

### **Monitoring des performances**

#### **MÃ©triques WireScanner**

```bash
# Voir les statistiques RSS
grep "feedsProcessed" logs/scraping.log | tail -10

# Analyser les temps de traitement
grep "session terminÃ©e" logs/scraping.log | tail -5
```

#### **MÃ©triques Cortex**

```bash
# Voir les articles analysÃ©s
grep "articles traitÃ©s" logs/scraping.log | tail -10

# Analyser l'utilisation mÃ©moire
grep "MÃ©moire" logs/debug.log | tail -10
```

#### **Alertes automatiques**

Le systÃ¨me gÃ©nÃ¨re automatiquement des alertes pour :

- ğŸ”¥ Utilisation mÃ©moire > 80%
- â° Traitement > 30 minutes
- âŒ Taux d'erreur > 10%
- ğŸ’¾ Espace disque faible

---

## ğŸ”§ **Scripts NPM disponibles** {#scripts}

### **Scripts principaux**

```bash
# ğŸš€ DÃ©marrage
npm start                    # DÃ©marrage complet du systÃ¨me
npm run dev                  # Mode dÃ©veloppement avec rechargement

# ğŸ•·ï¸ WireScanner
npm run wire-scanner         # WireScanner automatique (cron)
npm run scrapping           # WireScanner manuel

# ğŸ§  Cortex
npm run cortex              # Cortex automatique
```

### **Scripts de base de donnÃ©es**

```bash
# ğŸ§ª Tests
npm run db:test             # Test de connexion simple
npm run db:test-full        # Test complet avec toutes les tables
npm run db:health           # Ã‰tat de santÃ© dÃ©taillÃ©

# ğŸ“Š Informations
npm run db:stats            # Statistiques globales
npm run db:schema           # Structure des tables
npm run db:compatibility    # Test compatibilitÃ© ancien/nouveau code
```

### **Scripts de logs et diagnostic**

```bash
# ğŸ“‹ Logs
npm run logs:analyze        # Analyse complÃ¨te des logs
npm run logs:summary        # RÃ©sumÃ© des logs rÃ©cents
npm run logs:clean          # Nettoyage des anciens logs

# ğŸ” Diagnostic
npm run diagnostic          # Diagnostic complet du systÃ¨me
npm run diagnostic:quick    # Diagnostic rapide
```

### **Scripts de dÃ©veloppement**

```bash
# ğŸ› ï¸ DÃ©veloppement
npm run lint                # VÃ©rification du code
npm run format              # Formatage automatique
npm run test                # Tests unitaires (si configurÃ©s)

# ğŸ”„ Migration
npm run migrate:database    # Migration vers nouvelle couche database/
npm run migrate:cortex      # Migration Cortex vers v2.0
```

### **Scripts utilitaires**

```bash
# ğŸ§¹ Maintenance
npm run cleanup             # Nettoyage gÃ©nÃ©ral
npm run reset               # Reset complet (attention !)
npm run backup              # Sauvegarde de configuration

# ğŸ“Š Monitoring
npm run status              # Statut du systÃ¨me
npm run metrics             # MÃ©triques de performance
npm run health-check        # VÃ©rification santÃ©
```

---

## ğŸ› ï¸ **Migration et compatibilitÃ©** {#migration}

### **Migration de Bun vers Node.js**

Le projet a Ã©tÃ© **entiÃ¨rement migrÃ©** de Bun vers Node.js pour une meilleure compatibilitÃ© :

#### **Changements effectuÃ©s**

- âœ… `index.ts` â†’ `index.js`
- âœ… Configuration `package.json` mise Ã  jour
- âœ… Scripts npm complets
- âœ… Suppression des dÃ©pendances Bun
- âœ… Documentation mise Ã  jour

#### **Si vous venez d'une ancienne version**

```bash
# 1. Sauvegarder l'ancienne configuration
cp key.env key.env.backup

# 2. Nettoyer les anciennes dÃ©pendances
rm -rf node_modules package-lock.json

# 3. RÃ©installer avec npm
npm install

# 4. Tester la configuration
npm run diagnostic
```

### **Migration de la couche database**

#### **DÃ©tection automatique de l'ancien code**

Le systÃ¨me dÃ©tecte automatiquement l'utilisation de l'ancienne API et affiche des warnings :

```
âš ï¸ [MIGRATION] supabaseUtils.js est deprecated
   â†’ Utilisez: import { rssRepository } from '../database/index.js'
   â†’ Guide: DATABASE_MIGRATION_GUIDE.md
```

#### **Migration pas Ã  pas**

**Ã‰tape 1 : Identifier les fichiers Ã  migrer**

```bash
# Trouver les anciens imports
grep -r "supabaseUtils" . --include="*.js"
```

**Ã‰tape 2 : Remplacer les imports**

```javascript
// âŒ Ancien
import { getRssFeeds } from "./supabaseUtils.js";

// âœ… Nouveau
import { rssRepository } from "../database/index.js";
```

**Ã‰tape 3 : Adapter les appels de fonction**

```javascript
// âŒ Ancien
const feeds = await getRssFeeds();

// âœ… Nouveau
const feeds = await rssRepository.getAllFeeds();
```

**Ã‰tape 4 : Tester**

```bash
npm run db:compatibility
```

### **Migration Cortex vers v2.0**

#### **Migration automatique**

```javascript
import { migrateCortex } from "./Cortex/start.js";

const migrationResults = await migrateCortex({
  createBackup: true, // Sauvegarde avant migration
  testNewVersion: true, // Test de la v2.0
  preserveOldFiles: true, // Garde les anciens fichiers
});
```

#### **Migration manuelle**

```bash
# 1. VÃ©rifier la compatibilitÃ©
node -e "
import('./Cortex/migration.js').then(m => {
    m.cortexMigration.generateCompatibilityReport().then(console.log);
});
"

# 2. Lancer la migration si compatible
node -e "
import('./Cortex/start.js').then(m => {
    m.migrateCortex().then(console.log);
});
"
```

### **Migration WireScanner vers v2.0**

WireScanner v2.0 est **rÃ©trocompatible**. L'ancien et le nouveau code coexistent :

```
WireScanner/
â”œâ”€â”€ ğŸ“œ crawlUrl.js           # Version originale (fonctionnelle)
â”œâ”€â”€ ğŸš€ crawlUrl.optimized.js # Version v2.0 (optimisÃ©e)
â”œâ”€â”€ ğŸ“œ supabaseUtils.js      # Ancien (avec warnings)
â”œâ”€â”€ ğŸ†• dataManager.js        # Nouveau (recommandÃ©)
â””â”€â”€ ... (autres modules v2.0)
```

**Utilisation**

```javascript
// Utilise automatiquement la v2.0 si disponible
import { startWireScanner } from "./WireScanner/start.js";

// Force l'utilisation de la v1.0 (legacy)
import { crawlUrl as crawlUrlLegacy } from "./WireScanner/crawlUrl.js";
```

---

## ğŸ’¡ **Conseils pour dÃ©veloppeurs** {#tips}

### **ğŸ¯ Bonnes pratiques gÃ©nÃ©rales**

#### **1. Toujours utiliser les nouvelles APIs**

```javascript
// âœ… Bon - Utilise la nouvelle couche database
import { articleRepository } from "./database/index.js";

// âŒ Ã‰viter - Ancien code deprecated
import { getUrlArticle } from "./Cortex/supabaseUtils.js";
```

#### **2. GÃ©rer les erreurs correctement**

```javascript
try {
  const results = await scrapingFunction();
  logger.info(`SuccÃ¨s: ${results.length} Ã©lÃ©ments traitÃ©s`);
} catch (error) {
  logger.error(`Erreur scraping: ${error.message}`);
  // GÃ©rer l'erreur (retry, alerte, etc.)
}
```

#### **3. Utiliser le systÃ¨me de logs**

```javascript
import { logger } from "./utils/logger.js";

// Toujours spÃ©cifier le module
logger.info("DÃ©marrage traitement", "MonModule");

// Inclure des donnÃ©es contextuelles
logger.debug("RÃ©sultats", "MonModule", {
  count: results.length,
  duration: Date.now() - startTime,
});
```

#### **4. Surveiller les performances**

```javascript
// Mesurer les temps de traitement
const startTime = Date.now();
await processFunction();
const duration = Date.now() - startTime;

if (duration > 30000) {
  // Plus de 30 secondes
  logger.warning(`Traitement lent: ${duration}ms`, "MonModule");
}
```

### **ğŸ”§ DÃ©veloppement et dÃ©bogage**

#### **1. Activer les logs dÃ©taillÃ©s**

```bash
# Dans key.env
DEBUG=true
VERBOSE=true
CORTEX_LOG_LEVEL=DEBUG
```

#### **2. Tester en isolation**

```javascript
// Tester WireScanner seul
npm run scrapping

// Tester Cortex seul
npm run cortex

// Tester un module spÃ©cifique
node -e "import('./WireScanner/feedProcessor.js').then(m => m.processFeed('https://example.com/rss'))"
```

#### **3. Utiliser les outils de diagnostic**

```bash
# Diagnostic rapide
npm run diagnostic

# Focus sur un composant
npm run db:health      # Base de donnÃ©es
npm run logs:analyze   # Logs
```

#### **4. Surveiller la mÃ©moire en dÃ©veloppement**

```javascript
// Ajouter des checkpoints mÃ©moire
const checkMemory = () => {
  const usage = process.memoryUsage();
  console.log(`MÃ©moire: ${Math.round(usage.heapUsed / 1024 / 1024)}MB`);
};

// Surveiller avant/aprÃ¨s les opÃ©rations coÃ»teuses
checkMemory(); // avant
await heavyProcessingFunction();
checkMemory(); // aprÃ¨s
```

### **âš¡ Optimisations de performance**

#### **1. Configurer la concurrence selon votre systÃ¨me**

```javascript
// Dans WireScanner/config.js ou Cortex/config.js
export const PERFORMANCE_CONFIG = {
  // SystÃ¨me puissant
  MAX_CONCURRENT_ARTICLES: 5,
  BROWSER_POOL_SIZE: 3,

  // SystÃ¨me modeste
  MAX_CONCURRENT_ARTICLES: 2,
  BROWSER_POOL_SIZE: 1,
};
```

#### **2. Adapter les timeouts**

```javascript
// Pour sites lents
PAGE_TIMEOUT: 60000,  // 60 secondes

// Pour sites rapides
PAGE_TIMEOUT: 15000,  // 15 secondes
```

#### **3. GÃ©rer le cache intelligemment**

```javascript
// Cache agressif pour dÃ©veloppement
ARTICLE_CACHE_TTL: 3600000,  // 1 heure

// Cache conservateur pour production
ARTICLE_CACHE_TTL: 300000,   // 5 minutes
```

### **ğŸ”’ SÃ©curitÃ© et robustesse**

#### **1. Valider toutes les entrÃ©es**

```javascript
const validateUrl = (url) => {
  if (!url || typeof url !== "string") {
    throw new Error("URL invalide");
  }

  if (!url.startsWith("http")) {
    throw new Error("URL doit commencer par http/https");
  }

  return true;
};
```

#### **2. GÃ©rer les timeouts**

```javascript
const withTimeout = (promise, ms) => {
  return Promise.race([
    promise,
    new Promise((_, reject) =>
      setTimeout(() => reject(new Error("Timeout")), ms)
    ),
  ]);
};

// Utilisation
await withTimeout(scrapingFunction(), 30000); // 30s max
```

#### **3. ImplÃ©menter des retry intelligents**

```javascript
const retryWithBackoff = async (fn, maxRetries = 3) => {
  for (let i = 0; i < maxRetries; i++) {
    try {
      return await fn();
    } catch (error) {
      if (i === maxRetries - 1) throw error;

      const delay = Math.pow(2, i) * 1000; // Backoff exponentiel
      await new Promise((resolve) => setTimeout(resolve, delay));
    }
  }
};
```

---

## ğŸ› **DÃ©pannage** {#troubleshooting}

### **âŒ ProblÃ¨mes frÃ©quents et solutions**

#### **1. Erreurs de connexion base de donnÃ©es**

**SymptÃ´me**

```
âŒ Erreur connexion DB: Invalid API key
```

**Solution**

```bash
# 1. VÃ©rifier la configuration
cat key.env | grep SUPABASE

# 2. Tester la connexion
npm run db:test

# 3. VÃ©rifier les credentials sur Supabase
# â†’ Settings â†’ API â†’ anon/service_role keys
```

#### **2. Erreurs mÃ©moire Puppeteer**

**SymptÃ´me**

```
âŒ Error: Navigation timeout exceeded
âŒ Error: Protocol error: Target closed
```

**Solution**

```javascript
// Dans Cortex/config.js - RÃ©duire la charge
export const PERFORMANCE_CONFIG = {
  MAX_CONCURRENT_BROWSERS: 1, // Au lieu de 2
  MAX_CONCURRENT_ARTICLES: 1, // Au lieu de 3
  PAGE_TIMEOUT: 60000, // Augmenter timeout
};
```

#### **3. Erreurs de parsing RSS**

**SymptÃ´me**

```
âŒ Erreur parsing RSS: Invalid XML
```

**Solution**

```bash
# 1. Tester le flux RSS manuellement
curl -s "https://site.com/rss.xml" | head -20

# 2. VÃ©rifier les logs
grep "RSS parsing" logs/scraping.log | tail -10

# 3. Utiliser un validateur RSS
# â†’ https://validator.w3.org/feed/
```

#### **4. Process bloquÃ©**

**SymptÃ´me**

```
âš ï¸ Process bloquÃ© depuis > 30 minutes
```

**Solution**

```bash
# 1. Identifier le process
ps aux | grep node

# 2. ArrÃªter proprement
npm run stop
# ou forcer
pkill -f "node.*SentinelIQ"

# 3. RedÃ©marrer
npm run diagnostic
npm run scrapping
```

### **ğŸ” Outils de diagnostic**

#### **1. Diagnostic complet**

```bash
npm run diagnostic
```

**Ce que Ã§a vÃ©rifie :**

- âœ… Configuration `key.env`
- âœ… Connexion base de donnÃ©es
- âœ… Ã‰tat des tables
- âœ… Espace disque disponible
- âœ… MÃ©moire systÃ¨me
- âœ… Logs rÃ©cents

#### **2. Diagnostic spÃ©cialisÃ©**

```bash
# Focus base de donnÃ©es
npm run db:health

# Focus logs
npm run logs:analyze

# Focus mÃ©moire
node -e "console.log(process.memoryUsage())"

# Focus disque
df -h .
```

#### **3. Tests isolÃ©s**

```bash
# Tester un flux RSS spÃ©cifique
node -e "
import('./WireScanner/feedProcessor.js').then(m => {
    m.feedProcessor.processFeed('https://feeds.example.com/rss.xml')
        .then(console.log)
        .catch(console.error);
});
"

# Tester l'analyse d'un article
node -e "
import('./Cortex/scrapingEngine.js').then(m => {
    m.scrapingEngine.scrapeArticle('https://example.com/article')
        .then(console.log)
        .catch(console.error);
});
"
```

### **ğŸ“ Obtenir de l'aide**

#### **1. Informations Ã  collecter**

Avant de demander de l'aide, collectez :

```bash
# Version Node.js
node --version

# Logs rÃ©cents
tail -50 logs/error.log > debug-logs.txt

# Configuration (sans secrets)
cat key.env | grep -v KEY | grep -v PASSWORD

# Diagnostic complet
npm run diagnostic > diagnostic-report.txt

# Ã‰tat du systÃ¨me
free -h && df -h
```

#### **2. Logs utiles Ã  partager**

```bash
# Erreurs rÃ©centes uniquement
grep "ERROR\|âŒ" logs/*.log | tail -20

# DerniÃ¨re session de scrapping
grep -A 10 -B 5 "session.*terminÃ©e" logs/scraping.log | tail -30

# Statistiques de performance
grep "MÃ©moire\|Memory\|Performance" logs/debug.log | tail -10
```

#### **3. Tests reproductibles**

```bash
# Commande minimale pour reproduire le problÃ¨me
npm run scrapping 2>&1 | tee test-output.txt

# Test en mode debug
DEBUG=true VERBOSE=true npm run scrapping
```

---

## ğŸ“ **Conclusion**

### **Ce que vous avez appris**

- ğŸ—ï¸ **Architecture modulaire** : WireScanner + Cortex + Database
- âš¡ **Optimisations v2.0** : Performance, mÃ©moire, concurrence
- ğŸ’¾ **Couche database** : Repositories, compatibilitÃ©, migration
- ğŸ“Š **Monitoring** : Logs, mÃ©triques, diagnostic
- ğŸ”§ **Scripts NPM** : Automatisation, maintenance, tests
- ğŸ› ï¸ **DÃ©pannage** : ProblÃ¨mes frÃ©quents et solutions

### **Prochaines Ã©tapes recommandÃ©es**

1. **Commencer petit** : Testez d'abord `npm run diagnostic`
2. **ExpÃ©rimenter** : Lancez `npm run scrapping` avec quelques flux
3. **Optimiser** : Ajustez les configurations selon votre systÃ¨me
4. **Surveiller** : Analysez les logs avec `npm run logs:analyze`
5. **Migrer progressivement** : Passez Ã  la v2.0 de vos modules

### **Ressources supplÃ©mentaires**

- **Documentation officielle** : README.md pour les bases
- **Guides spÃ©cialisÃ©s** : DATABASE_MIGRATION_GUIDE.md, CHANGELOG.md
- **Scripts d'aide** : `npm run` pour voir tous les scripts disponibles
- **Logs en temps rÃ©el** : `tail -f logs/scraping.log`

**ğŸš€ Bon dÃ©veloppement avec SentinelIQ Harvest !**

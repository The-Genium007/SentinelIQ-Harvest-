import { getRssFeeds, testSupabaseConnection, articleExists, insertArticle } from './supabaseUtils.js';
import { parseFeed, isValidUrl } from './rssUtils.js';

/**
 * Fonction principale pour crawler les flux RSS et ins√©rer les nouveaux articles dans la base Supabase.
 * - R√©cup√®re la liste des flux RSS depuis Supabase
 * - Pour chaque flux, parse les articles
 * - Ins√®re les nouveaux articles non pr√©sents dans la base
 */
export async function crawlUrl() {
    // R√©cup√©ration des URLs de flux RSS depuis la table ListUrlRss de Supabase
    const sources = await getRssFeeds();
    // V√©rification de la connexion √† Supabase
    await testSupabaseConnection();

    let totalArticlesInserted = 0; // Compteur pour les articles ins√©r√©s

    // Parcours de chaque source RSS r√©cup√©r√©e depuis la base
    for (const source of sources) {
        // V√©rification de la validit√© de l'URL
        if (!isValidUrl(source.url)) {
            console.warn(`‚ö†Ô∏è URL invalide ignor√©e : ${source.url}`);
            continue;
        }

        console.log(`üì• Lecture de ${source.url}`);
        try {
            // Parsing du flux RSS
            const feed = await parseFeed(source.url);
            // Parcours de chaque article du flux
            for (const item of feed.items) {
                const articleUrl = item.link;
                // V√©rifie que l'URL de l'article est valide
                if (articleUrl && isValidUrl(articleUrl)) {
                    try {
                        // V√©rifie si l'article existe d√©j√† dans la base
                        if (!(await articleExists(articleUrl))) {
                            // Insertion de l'article s'il n'existe pas
                            await insertArticle(articleUrl);
                            totalArticlesInserted++; // Incr√©mente le compteur
                            console.log(`‚úÖ Article ins√©r√© : ${articleUrl}`);
                        } else {
                            // L'article existe d√©j√†
                            console.log(`üîÅ Article d√©j√† pr√©sent : ${articleUrl}`);
                        }
                    } catch (err) {
                        // Affiche une erreur si la v√©rification ou l'insertion √©choue
                        console.error(err.message);
                    }
                }
            }
        } catch (err) {
            // Affiche un avertissement si le parsing du flux √©choue
            console.warn(`‚ùå Erreur lors du traitement du flux : ${source.url}`, err.message);
        }
    }

    // Log de fin de scrapping
    logScrapingCompletion(sources.length, totalArticlesInserted);
}

/**
 * D√©tecte la fin du scrapping et log un message de confirmation.
 * @param {number} totalSources - Nombre total de sources trait√©es
 * @param {number} totalArticles - Nombre total d'articles ins√©r√©s
 */
function logScrapingCompletion(totalSources, totalArticles) {
    console.log(`‚úÖ Scrapping termin√© : ${totalSources} sources trait√©es, ${totalArticles} articles ins√©r√©s.`);
}